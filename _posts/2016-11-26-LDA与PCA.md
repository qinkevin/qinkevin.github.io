---
layout: post
title: "LDA(线性判别分析)与PCA(主成分分析)"       # Title of the post
subtitle:
date:       2016-11-26 12:00:00
author:     "随机漫步的傻瓜"
header-img: "img/post-bg-2015.jpg"
catalog: true
tags:
    - 机器学习
---

# LDA（线性判别分析）
- LDA的全称是Linear Discriminant Analysis（线性判别分析）是一种supervised learning，也称为Fisher's Linear Discriminant.
- LDA的原理是，将带上标签的数据（点），通过投影的方法，投影到维度更低的空间中，使得投影后的点，会形成按类别区分，一簇一簇的情况，相同类别的点，将会在投影后的空间中更接近。分类的目标是，使得类别内的点距离越近越好（集中），类别间的点越远越好
- 损失函数是组间与组内的比

#PCA（主成分分析）
- 主成分分析（PCA）与LDA有着非常近似的意思，LDA的输入数据是带标签的，而PCA的输入数据是不带标签的，所以PCA是一种unsupervised learning。LDA通常来说是作为一个独立的算法存在，给定了训练数据后，将会得到一系列的判别函数（discriminate function），之后对于新的输入，就可以进行预测了。而PCA更像是一个预处理的方法，它可以将原本的数据降低维度，而使得降低了维度的数据之间的方差最大
- PCA有两种思路，一种是最大化投影后的误差，另一种是最小化投影后的损失
- PCA： To project the original data to the eigenvectors of S with the largest eigenvalues
