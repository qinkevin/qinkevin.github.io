---
layout: post
title: "强化学习入门"       # Title of the post
subtitle:
date:       2017-04-24 12:00:00
author:     "随机漫步的傻瓜"
header-img: "img/post-bg-2015.jpg"
catalog: true
tags:
    - 机器学习
---

# MDP
- 强化学习的基本原理：智能体在完成某项任务时，首先通过动作A与周围环境进行交互，在动作A和环境的作用下，智能体会产生新的状态，同时环境会给出一个立即回报。如此循环下去，智能体与环境进行不断地交互从而产生很多数据。强化学习算法利用产生的数据修改自身的动作策略，再与环境交互，产生新的数据，并利用新的数据进一步改善自身的行为，经过数次迭代学习后，智能体能最终学到完成相应任务的最优动作（最优策略）
- 强化学习的学习过程是个动态的，不断交互的过程，所需要的数据也是通过与环境不断地交互产生的。深度学习如图像识别和语音识别解决的是感知的问题，强化学习解决的是决策的问题。
- 所谓马尔科夫性是指系统的下一个状态仅与当前状态有关，而与以前的状态无关
- 这表明当前状态其实是蕴含了所有相关的历史信息，一旦当前状态已知，历史信息将会被抛弃
- 若随机变量序列中的每个状态的马尔科夫的则称此随机过程为马尔科夫随机过程
- 马尔科夫过程是一个二元组（S,P），且满足：S是有限状态集合，P是状态转移概率
- 将动作（策略）和回报考虑在内的马尔科夫过程称为马尔科夫决策过程
- 马尔科夫决策过程由元组(S,A,P,R,r)描述，其中：S为有限的状态集，A为有限的动作集，P为状态转移概率，R为回报概率，r为折扣因子，用来计算累积回报。注意，跟马尔科夫过程不同的是，马尔科夫决策过程的状态转移概率是包含动作的
