---
layout:     post
title:      "项目面试准备"
subtitle:
date:       2017-7-13 11:00:00
author:     "随机漫步的傻瓜"
header-img: "img/post-bg-2015.jpg"
catalog: true
tags:
    - 其他
---
#百度实习
## 规则
- 不一致性检测（一个bssid对应多个ssid）、异常检测（一个cuid对应过少或过多ip）、与异常实体有较多关联（登陆过模拟器的账户）
- 优点：性能高、易于理解和分析、开发相对简单
- 缺点：一刀切，容易被薅羊毛的人嗅探到；规则冲突问题
## 图计算
- Label propagation、PageRank、Triangle count
- LPA算法的终止条件要求所有node的label一定是它的邻居label中出现次数最多的
- LPA不需要太多计算资源，但是并不一定会收敛且可能不准确
- 主要为迭代次数
## 机器学习
- 目的：识别风险设备
- 数据量：7千万，负样本70万
- 特征：设备基本信息（是否模拟器、是否root设备、是否改码工具、是否注入调试等）、规则特征（设备所在bssid下root设备占比、模拟器占比、设备所在ip下root设备占比、模拟器占比）、图结构特征（设备所属团伙的拓扑特征、团伙的实体特征）、设备活跃特征（设备连接的bssid数、周、月）、交叉特征、one-hot encoder、gbdt自动特征
- 标签：使用过去30天是否被规则引擎命中
- 模型： xgboost、xgboost+LR、gcForest
- 最终效果： AUC 0.7、准确率 0.98、召回率 0.2。
- 注意点：GBDT和LR使用的是不同的数据,GBDT树的深度为3，树的个数为1000

# 融360贷款预测比赛
- 将不同方法的平均重要度作为最终参考指标，筛选掉得分低的特征。
- 为了解某个模型在犯什么错误，我们可以观察被模型误判的样本，总结它们的共同特征，我们就可以再训练一个效果更好的模型
- 如果数据出现Label不均衡情况，可以使用Stratified K-fold，这样得到的Train Set和Test Set的Label比例是大致相同。
- 在实现Stacking时，要注意的一点是，避免标签泄漏(Label Leak)。在训练次学习器时，需要上一层学习器对Train Data的测试结果作为特征。如果我们在Train Data上训练，然后在Train Data上预测，就会造成Label Leak。为了避免Label Leak，需要对每个学习器使用K-fold，将K个模型对Valid Set的预测结果拼起来，作为下一层学习器的输入。可以将K个模型对Test Data的预测结果求平均，也可以用所有的Train Data重新训练一个新模型来预测Test Data.

#信用卡评分
- 大量人工特征，将连续特征离散化，并对离散化的特征进行One-Hot编码，最后对特征进行二阶或者三阶的特征组合，目的是为了得到非线性的特征。连续变量切分点如何选取？离散化为多少份合理？选择哪些特征交叉？多少阶交叉，二阶，三阶或更多？一般都是按照经验，不断尝试一些组合，然后根据线下评估选适当参数
#文本聚类
#红牛工作
