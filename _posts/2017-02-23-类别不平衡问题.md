---
layout: post
title: "类别不平衡问题"       # Title of the post
subtitle:
date:       2017-02-23 15:00:00
author:     "随机漫步的傻瓜"
header-img: "img/post-bg-2015.jpg"
catalog: true
tags:
    - 机器学习
---

- 类别不平衡问题就是指分类任务中不同类别的训练样例数目差别很大的情况
- 对于类别不平衡问题，用传统算法解决会比较困难，因为传统的算法通常是偏向数量占优的类，因为它们的损失函数会试图最优化相关数量，例如错误率，而没有将数据分布纳入考虑范围内
- 常用的方法有过采样、欠采样、调整类别权重、阀值移动
- 在类别不平衡问题中不能使用准确度来衡量，应该使用ROC等
- 过采样会随机复制少数样例以增大它们的规模。欠采样则随机地少采样主要的类。一些数据科学家（天真地）认为过采样更好，因为其会得到更多的数据，而欠采样会将数据丢掉。但请记住复制数据不是没有后果的——因为其会得到复制出来的数据，它就会使变量的方差表面上比实际上更小。而过采样的好处是它也会复制误差的数量：如果一个分类器在原始的少数类数据集上做出了一个错误的负面错误，那么将该数据集复制五次之后，该分类器就会在新的数据集上出现六个错误。相对地，欠采样会让独立变量（independent variable）的方差看起来比其实际的方差更高。
- 调整类的权重，Scikit-learn 有许多可以使用可选的 class_weight 参数（可以设置成大于 1）的分类器
- 欠采样即去除一些反例使得正、反例数目接近，然后进行学习。欠采样法若随机丢弃反例，可能丢失一些重要信息
- 过采样，增加一些正例使得正反样例数目接近，然后再进行学习。过采样不能简单地对初始正例样本进行重复采样，否则会招致严重的过拟合。过采样的代表性算法是SMOTE，该算法通过对训练集里的正例进行插值来产生额外的正例。
- 阀值移动，直接基于原始训练集进行学习，但在用训练好的分类器进行预测时，调整阀值
- 阈值较小，意味着我们的模型非常严格宁肯错杀也不肯放过，这样会使得绝大多数样本都被当成了异常的样本，recall很高，精度稍低;当阈值较大的时候我们的模型就稍微宽松些啦，这个时候会导致recall很低，精度稍高
