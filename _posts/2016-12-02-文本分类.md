---
layout: post
title: "文本分类"       # Title of the post
subtitle:
date:       2016-12-02 22:00:00
author:     "随机漫步的傻瓜"
header-img: "img/post-bg-2015.jpg"
catalog: true
tags:
    - 机器学习
---

# 文本分类
- 首先大家都有这样一种认知假设，即意思相近的词语，它在文本中出现的上下文也是相似的，也就是说，相似的词语拥有相似的语境。因此，我们可以利用一个词语的上下文，如一个词语与其它词语共同出现的次数，这样一个次数组成的向量，来表示这个词语。当然，如果句子特别长，我们可以限定窗口，只取该单词前后 n 个单词的词共现次数来表示这个单词
- 与之前一般的共现计数不同，word2vec 作为现在主流的词嵌入算法，主要是通过预测一个窗口长度为 c 的窗口内每个单词的周边单词概率，来作为这个单词的词向量。通过这种方式，把单词映射到一个高维向量空间，借此可以计算单词之间的距离，即计算语义相似性
- 在 word2vec 中使用最重要的两个模型分别是 CBOW 和 Skip-gram 模型，前者是利用词的上下文预测当前的单词，后者则是利用当前词来预测上下文
- CBOW 全称是 Continuous Bag-of-Words Model，即连续的词袋，因为它用连续空间来表示词，而且这些词的先后顺序并不重要
