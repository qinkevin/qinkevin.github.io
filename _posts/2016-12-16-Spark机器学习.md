---
layout:     post
title:      "Spark机器学习"
subtitle:
date:       2016-12-16 20:00:00
author:     "随机漫步的傻瓜"
header-img: "img/post-bg-2015.jpg"
catalog: true
tags:
    - 大数据
---

# 第一章 Spark的环境搭建与运行
- Spark从一开始便为应对迭代式应用的高性能需求而设计。在这类应用中，相同的数据会被多次访问。该设计主要靠利用数据集内存缓存以及启动任务时的低延迟和低系统开销来实现高性能
- 任何Spark程序的编写都是从SparkContext开始的
- 一个RDD代表一系列的“记录”（严格来说，某种类型的对象）。这些记录被分配或分区到一个集群的多个节点上（在本地模式下，可以类似地理解为单个进程里的多个线程上）。Spark中的RDD具备容错性，即当某个节点或任务失败时（因非用户代码错误的原因而引起，如硬件故障、网络不通等），RDD会在余下的节点上自动重建，以便任务能最终完成
- 在Spark编程模式下，所有的操作被分为转换(transformation)和执行(action)两种。一般来说，转换操作是对一个数据集里的所有记录执行某种函数，从而使记录发生改变；而执行通常是运行某些计算或聚合操作，并将结果返回运行SparkContext的那个驱动程序
- Spark程序中最常用的转换操作便是map操作。该操作对一个RDD里的每一条记录都执行某个函数，从而将输入映射称为新的输出
- 在Scala中=>表示匿名函数。语法line => line.size表示以=>操作符左边的部分作为输入，对其执行一个函数，并以=>操作符右边代码的执行结果为输出。
- 另一个常见的执行操作是count,来返回RDD中的记录数目
- Spark的大多数操作都会返回一个新RDD，但多数的执行操作则是返回计算的结果。这就意味着多个操作可以很自然地前后连接，从而让代码更为简洁明了
- 值得注意的一点是，Spark中的转换操作是延后的。也就是说，在RDD上调用一个转换操作并不会立即触发相应的计算。相反，这些转换操作会链接起来，并只在有执行操作被调用时才被高效地计算。这样，大部分操作可以在集群上并行执行，只有必要时才计算结果并将其返回给驱动程序，从而提高了Spark的效率。这就意味着，如果我们的Spark程序从未调用一个执行操作，就不会触发实际的计算，也不会得到任何结果
- Spark最为强大的功能之一便是能够把数据缓存在集群的内存里。这通过调用RDD的cache函数来实现。
- 广播变量(broadcast variable)为只读变量，它由运行SparkContext的驱动程序创建后发送给会参与计算的节点。对那些需要让各工作节点高效地访问相同数据的应用场景，比如机器学习，这非常有用。广播变量也可以被非驱动程序所在的节点（即工作节点）访问，访问的方法是调用该变量的value方法
- 通常只在需将结果返回到驱动程序所在节点以供本地处理时，才调用collect函数。注意，collect函数一般仅在的确需要将整个结果集返回驱动程序并进行后续处理时才有必要调用。如果在一个非常大的数据集上调用该函数，可能耗尽驱动程序的可用内存，进而导致程序崩溃。高负荷的处理应尽可能地在整个集群上进行，从而避免驱动程序称为系统瓶颈。然而在不少情况下，将结果收集到驱动程序的确是有必要的。很多机器学习算法的迭代过程便属于这类情况
- 累加器(accumulator)也是一种被广播到工作节点的变量。累加器与广播变量的关键不同，是后者只能读取而前者却可累加。但支持的累加操作有一定的限制。具体来说，这种累加必须是一种有关联的操作，即它得能保证在全局范围内累加起来的值能被正确地并行计算以及返回驱动程序。每一个工作节点只能访问和操作其自己本地的累加器，全局累加器则只允许驱动程序访问。累加器同样可以在Spark代码中通过value访问
- 在实际处理大量数据时，我们通常通过sortByKey这类操作来对其进行并行排序

# 第二章 设计机器学习系统
- 然而我们所处理的通常是大型数据集。这样，先在具有代表性的小样本数据集上进行初步的训练-测试回路，或是尽可能并行地选择模型，都会有所帮助
- 现实中应该同时监控模型准确度相关指标和业务指标
- 模型反馈(model feedback)，指通过用户的行为来对模型的预测进行反馈的过程。在现实系统中，模型的应用将影响用户的决策和潜在行为，从而反过来将从根本上改变模型自己将来的训练数据
- 好在我们可以借助一些机制来降低反馈回路的这种负面影响，比如提供一些无偏见的训练数据。这类数据来自那些没有被推荐的用户，又或者在一开始就考虑到这种平衡需求而划分出来的客户。这些机制有助于对数据的理解、探索以及利用已有的经验来提升系统的表现
- 在线学习在新数据到达时便能立即更新模型，从而使实时系统成为可能。这类方法的优势在于其系统将能对新的信息和底层行为（即输入数据的特征或是分布会随时间变化，现实中的绝大部分情况都会如此）作出快速的反应和调整
- 现实中的实时机器学习系统具有天生的复杂性，故实践中大部分的系统都以近实时性为设计目标。这是一种混合方法，它并不要求模型一定在数据到达时立即更新。相反，新的数据会被收集为小批量的训练数据，再输入给在线学习算法。大部分情况下，该方法会周期性地进行某种批处理。处理的内容可能包括在整个数据集上重新计算模型，或是更为复杂的某些数据处理以及模型的选择。这些能保证实时模型的表现不会随时间推移而变差。
-  另一种类似的方法是，在周期性批处理中进行重新计算时，若有新的数据到来则只对更复杂的模型进行近似更新。这样模型可从新的数据学习，但有短暂延迟。因为是近似更新，所以模型的准确度会随着时间推移而下降。但周期性地在所有数据上重新计算模型能弥补这一点

# 第三章 Spark上数据的获取、处理与准备
- Spark与ipython结合：cd spark  PYSPARK_DRIVER_PYTHON=ipython ./bin/pyspark
- Spark与ipython notebook结合：cd spark PYSPARK_DRIVER_PYTHON=ipython  PYSPARK_DRIVER_PYTHON_OPTS=notebook ./bin/pyspark
- collect():Return all the elements of the dataset as an array at the driver program. This is usually useful after a filter or other operation that returns a sufficiently small subset of the data.
- count():统计RDD中元素的个数
- countByKey():与count类似，但是是以key为单位进行统计。注意：此函数返回的是一个map，不是int
- countByValue():统计一个RDD中各个value的出现次数。返回一个map，map的key是元素的值，value是出现的次数。
- first函数与collect函数类似，但前者只向驱动程序返回RDD的首个元素。我们也可以使用take(k)函数来只返回RDD的前k个元素到驱动程序
- matplotlib中hist函数中normed=True参数会正则化直方图，即表示百分比
- 对那些可能存在异常值或值域覆盖过大的特征，利用如对数或高斯核对其转换。这类转换有助于降低变量存在的值跳跃的影响，并将非线性关系变为线性的
- 数值特征到类别特征的转换也很常见，比如划分为区间特征。进行这类转换的变量常见的有年龄、地理特征和时间
- zipWithIndex函数将RDD中的元素和这个元素在RDD中的ID（索引号）组合成键/值对
- 正则化特征向量：通常是对数据中的某一行的所有特征进行转换，以让转换后的特征向量的长度标准化。也就是缩放向量中的各个特征以使得向量的范数为1

# 第四章 构建基于Spark的推荐引擎
- 基于用户与物品的方法的得分取决于若干用户或是物品之间依据相似度所构成的集合（即邻居），故它们也常被称为最近邻模型
- 推荐系统和协同过滤模型里常用的两个指标：均方误差(MSE)及K值平均准确率
- 均方误差的定义为各平方误差的和与总数目的商。其中平方误差是指预测到的评级与真实评级的差值的平方
- 均方根误差(RSME)只需在MSE上取平方根即可。
- K值平均准确率(MAPK)的意思是整个数据集上的K值平均准确率(APK)的均值。APK用于衡量针对某个查询所返回的“前K个”文档的平均相关性。对于每次查询，我们会将结果中的前K个与实际相关的文档进行比较
- 当用APK来做评估推荐模型时，每一个用户相当于一个查询，而每一个“前K个”推荐物组成的集合则相当于一个查到的文档结果集合。

# 第五章 Spark构建分类模型
- 对于二分类来说，逻辑回归的输出等价于模型预测某个数据点属于正类的概率估计
- 注意模型预测的值并不是恰好为1或0.预测的输出通常是实数，然后必须转换为预测类别。这是通过在分类器决策函数或打分函数中使用阈值来实现的
- 直觉上来讲，当阈值低于某个程度，模型的预测结果永远会是类别1.因此，模型的召回率为1，但是准确率很可能很低。相反，当阈值足够大，模型的预测结果永远会是类别0.此时，模型的召回率为0，但是因为模型不能预测任何真阳性的样本，很可能会有很多的假阴性样本。不仅如此，因为这种情况下真阳性和假阳性为0，所以无法定义模型的准确率。
- ROC曲线上每一个点代表分类器决策函数中不同的阈值
- 虽然原始特征是稀疏的（大部分维度是0），但对每个项减去均值之后，将得到一个非稀疏（稠密）的特征向量表示。数据规模比较小的时候，稀疏的特征不会产生问题，但实践中往往大规模数据是非常稀疏的。此时，不建议丢失数据的稀疏性，因为相应的稠密表示所需要的内存和计算量将爆炸性增长。此时标准化时只除以标准差，不会减去均值
- 在梯度下降中较大的步长收敛较快，但是步长太大可能导致收敛到局部最优解
- 注意决策树通常不需要特征的标准化和归一化，也不要求将类型特征进行二元编码
- 在实际中，会创建三个数据集：训练集、评估集（用于模型参数的调优）和测试集（用于估计模型在新数据中性能）
- 在交叉验证中，我们一般选择测试集中性能表现最好的参数设置（包括正则化以及步长等各种各样的参数）。然后用这些参数在所有的数据集上重新训练，最后用于新数据集的预测

# 第六章 Spark构建回归模型
- 类似线性回归模型需要使用对应损失函数，决策树在用于回归时也要使用对应的不纯度度量方法。这里的不纯度度量方法是方差，和最小二乘回归模型定义方差损失的方式一样
- MAE（平均绝对误差）是预测值和实际值的差的绝对值的平均值
- RMSLE（均方根对数误差）可以认为是对预测值和目标值进行对数变换后的RMSE。这个度量方法适用于目标变量值域很大，并且没有必要对预测值和目标值的误差进行惩罚的情况。另外，它也适用于计算误差的百分率而不是误差的绝对值
- R-平方系数，也称判定系数，用来评估模型拟合数据的好坏，常用于统计学中。R-平方系数具体测量目标变量的变异度，最终结果为0到1的一个值，1表示模型能够完美契合数据
- 许多机器学习模型都会假设输入数据和目标变量的分布，比如线性模型的假设为正态分布。但实际很多并不符合。一种解决方法是对目标变量进行变换，比如用目标值的对数代替原始数值，通常称为对数变换（这种变换也可以应用到特征值上）。另一种有用的变换是取平方根，适用于目标变量不为负数并且值域很大的情况
- 通常来讲，步长和迭代次数的设定需要权衡。较小的步长意味着收敛速度慢，需要较大的迭代次数。但是较大的迭代次数更加耗时，特别是在大数据上

# 第七章 Spark构建聚类模型
- 通常无监督学习会和监督模型相结合，比如使用无监督技术为监督模型生成输入数据
- 混合模型本质上是模糊K-均值的扩展，但是混合模型假设样本的数据是由某种概率分布产生的。类簇的分布是软分配，所以每个样本由K个概率分布的权重表示
- K-均值和最小方差回归一样使用方差函数作为优化目标，因此容易受到离群值和较大方差的特征影响。对于回归和分类问题来说，上述问题可以通过特征的归一化和标准化来解决，同时可能有助于提升性能。但是某些情况下我们可能不希望数据被标准化，比如根据某个特定的特征找到对应的类簇
- 检验分类结果的具体方法很多，可以通过重点解释每个类簇中靠近类中心的一些点，通常认为选择这些点对所分配的簇争议最小
- 聚类的评估通常分为两部分：内部评估和外部评估。内部评估表示评估过程使用训练模型时使用的训练数据，外部评估则使用训练数据之外的数据
- 通常的内部评价指标包括WCSS、Davies-Bouldin指数、Dunn指数和轮廓系数。所有这些度量指标都是使类簇内部的样本距离尽可能接近，不同类簇的样本相对较远
- 因为聚类被认为是无监督分类，如果有一些带标注的数据，便可以用这些标签来评估聚类模型。可以使用聚类模型预测类簇，使用分类模型中类似的方法评估预测值和真实标签的误差

# 第八章 Spark应用于数据降维
- 一般计算截断的SVD。只保留前k个奇异值，它们能代表数据的最主要变化，剩余的奇异值被丢弃
- 在协同过滤的例子中，矩阵分解负责把评分矩阵分解成两部分：用户矩阵和商品矩阵。两者都具有比原始数据更低的维度，所以这些方法也是减少维度的模型
- 每一个彩色图片可以表示成一个三维的像素数组或矩阵。前两维，即x、y坐标，表示每个像素的位置，第三个维度表示像素的红、蓝、绿（RGB）三元色的值
- 一个灰度图片每个像素仅仅需要一个值（不需要RGB值）来表示，因此可以简单表示为二维矩阵。很多和图片相关的图像处理和机器学习任务经常只处理灰度图片。
- 在机器学习中。还有一种常用的方式是把图片表示成一个向量，而不是矩阵。我们通过连接矩阵的每一行（或者每一列）来形成一个长向量（称为重塑）。这样每一个灰度图像矩阵会被转换为矩阵向量，作为机器学习模型的输入
- SVD计算产生的右奇异向量等同于PCA的主成分
- SVD与PCA都确定可以返回多个主成分或者奇异值，因此控制模型的唯一参数就是k。就像聚类模型，增加k总是可以提高模型的表现。因此，选择k的值需要折中，看是要包含尽量多的数据的结构信息，还是要保持投影数据的低维度。

# 第九章 Spark高级文本处理技术
- TF-IDF公式的含义是：在一个文档中出现次数很多的词相比出现次数少得词应该在词向量表示中得到更高的权值。而IDF归一化起到了减弱在所有文档中总是出现的词的作用。最后的结果就是，稀有的或者重要的被给予了更高的权重，而更加常用的单词（被认为比较不重要）则在考虑权重的时候有较小的影响
- 特征哈希是一种处理高维数据的技术，并经常被应用在文本和分类数据集上，这些数据集的特征可以取很多不同的值。
- 构造使用k分之一特征编码需要在一个向量中维护可能的特征值到下标的映射。另外，构建这个映射的过程本身至少需要额外对数据集的一次遍历，这在并行场景下会比较麻烦。
- 特征哈希通过使用哈希方程对特征赋予向量下标，这个向量下标是通过对特征的值做哈希得到的（通常是整数）
- 在文本处理中可以删除那些出现频率较少的单词
- 在文本分类中，我们可能希望通过使用分类模型学习每个单词的权重，来得到某些单词出现（及权重）情况到特定主体的映射；可以用来区分不同主题的文档。也就是说，应该可以学习到一个从某些单词是否出现（和权重）到特定主题的映射关系
- 注意，有一点很重要，我们使用训练集的IDF来转换测试集，这会在新数据集上产生更加真实的模型估计，因为新的数据集上包含训练集没有训练的单词。如果基于测试集重新计算IDF向量会比较“取巧”，且更重要的是，有可能对通过交叉验证产生的模型最优参数做出非常严重的错误估计

# 第十章 Spark Streaming在实时机器学习上的应用
- 相比于离线计算，在线学习是以对训练数据通过完全增量的形式顺序处理一遍为基础（就是说，一次只训练一个样例）。当处理完每一个训练样本，模型会对测试样例做预测并得到正确的输出（例如得到分类的标签或者回归的真实目标）。在线学习背后的想法就是模型随着接收到新的消息不断更新自己，而不是像离线训练一次次重新训练
- 在某种而配置下，当数据量很大的时候，或者生成数据的过程快速变化的时候，在线学习方法可以快速接近实时地响应，而不需要离线学习中昂贵的重新训练
- 批量处理的方法一般包括保存数据流到一个临时的存储系统（如HDFS或数据库）和在存储的数据上运行批量处理。为了生成最新的结果，批量处理必须在最新的可用数据上周期性地运行（每天、每小时，甚至几分钟一次）
- 相反，流处理方法是当数据产生时就开始处理，接近实时（从不足一秒到十几分之一秒，而非批处理的以分钟、小时、天，甚至周计）。
处理流计算有几种通用的技术，其中最常见的两种如下：单独处理每条记录，并在记录出现时立刻处理；把多个记录组合为小批量任务，可以通过记录数量或者时间长度切分出来
- Spark Streaming 使用第二种方法，其核心概念是离散化流，或DStream。一个DStream是指一个小批量作业的序列，每一个小批量作业表示为一个Spark RDD.
- 离散化流是通过输入数据源和叫做批量处理间隔的时间窗口来定义的。数据流被分成和批处理间隔相等的时间段（从应用开始执行开始）。流中每一个RDD将包含从Spark Streaming 应用程序接收到的一个批处理时间段内的记录。如果在所给时间段内没有数据产生，将得到一个空的RDD。
- Spark Streaming 接收端负责从数据源接收数据并转换成由Spark RDD组成的DStream。
- Spark Streaming 还提供了reduce 和count 这样的算子，它们返回由一个元素（如每批的数目）组成的DStream对象。并不像RDD上的操作，这些算子不会直接触发DStream计算。也就是说，它们不是动作，但仍是转换，因为会返回另一个DStream。
- Spark Streaming自己有一套在DStream之上执行算子的概念。执行算子是输出算子，调用时会触发DStream之上的计算。
- forEachRDD允许用户对DStream的每一个批量数据对应的RDD本身做任意操作
- 因为Spark Streaming 基于时间顺序批量处理数据流，所以引入了一个新的概念，叫做时间窗。时间窗函数计算在流上的滑动窗口中的数据转换。窗口由窗口长度和滑动间隔定义。
- 使用Spark的流处理元素结合MLlib的基于SGD的在线学习能力，可以创建实时的机器学习模型，当数据流到达时实时更新学习模型
- 机器学习和Spark Streaming组合起来有很多潜在的应用场景。包括保证模型和模型集合在新的训练数据上同步更新，因而使模型能很快适应上下文场景的改变
- 另一个有用的实例就是以在线方式跟踪和比较多个模型的性能，甚至可能实时执行模型选择，从而总是用性能最好的模型来生成在线数据的预测结果
