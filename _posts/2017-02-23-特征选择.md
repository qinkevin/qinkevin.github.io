---
layout: post
title: "特征选择"       # Title of the post
subtitle:
date:       2017-02-23 15:00:00
author:     "随机漫步的傻瓜"
header-img: "img/post-bg-2015.jpg"
catalog: true
tags:
    - 机器学习
---

特征选择是指选择获得相应模型和算法最好性能的特征集
- 1.计算每一个特征与响应变量的相关性：工程上常用的手段有计算皮尔逊系数和互信息系数
- 2.构建单个特征的模型，通过模型的准确性为特征排序，借此来选择特征
- 3.通过L1正则项来选择特征：L1正则方法具有稀疏解的特性，因此天然具备特征选择的特性，但是要注意，L1没有选到的特征不代表不重要，原因是两个具有高相关性的特征可能只保留了一个，如果要确定哪个特征重要应再通过L2正则方法交叉检验
- 4.训练能够对特征打分的预选模型：RandomForest和Logistic Regression等都能对模型的特征打分，通过打分获得相关性后再训练最终模型；
- 5.通过特征组合后再来选择特征：如对用户id和用户特征最组合来获得较大的特征集再来选择特征，这种做法在推荐系统和广告系统中比较常见，这也是所谓亿级甚至十亿级特征的主要来源，原因是用户数据比较稀疏，组合特征能够同时兼顾全局模型和个性化模型
- 6.基于树的模型会使用基尼不纯度等进行选择（其中randomForest以及xgboost里的方法可以判断features的Importance）
- 7.PCA等方法可以生成指定数量的新features
- 8.擅对features进行visualization或correlation的分析
